{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import argparse\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from eval_metrics import ErrorRateAt95Recall\n",
    "from models import HardNet, ResNet, SOSNet32x32\n",
    "from dataset import TripletPhotoTour, BrownTest\n",
    "from losses import loss_HardNet, loss_L2Net\n",
    "from utils import cv2_scale, np_reshape, read_yaml\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "\n",
      "================ IMAGE MATCHING CHALLENGE 2020 ==================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info('\\n\\n================ IMAGE MATCHING CHALLENGE 2020 ==================\\n\\n')\n",
    "configs = read_yaml('configs.yml')\n",
    "# models_output = os.path.join('models', configs['experiment_name'])\n",
    "os.makedirs(configs['model_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if configs['use_cuda']:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(configs['gpu_id'])\n",
    "    cudnn.benchmark = True\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_id, data in tqdm(enumerate(train_loader)):\n",
    "        if batch_id + 1 == len(train_loader):\n",
    "            continue\n",
    "        data_a, data_p = data\n",
    "\n",
    "        if configs['use_cuda']:\n",
    "            data_a, data_p  = data_a.cuda(), data_p.cuda()\n",
    "        out_a = model(data_a)\n",
    "        out_p = model(data_p)\n",
    "\n",
    "        loss = loss_HardNet(out_a, out_p)\n",
    "           \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_id%10 == 0:\n",
    "            logging.info(f'{batch_id}/{len(train_loader)} - Loss: {loss.item()}')\n",
    "        if batch_id%100 == 0:\n",
    "            x = datetime.datetime.now()\n",
    "            time = x.strftime(\"%y-%m-%d_%H:%M:%S\")\n",
    "            model_checkpoint = os.path.join(configs['model_dir'], f'checkpoint_{time}_{epoch}_{batch_id}.pth')\n",
    "            torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict()}, model_checkpoint)\n",
    "            logging.info(model_checkpoint)\n",
    "    logging.info(f'{len(train_loader)}/{len(train_loader)} - Loss: {loss.item()}')\n",
    "    \n",
    "    x = datetime.datetime.now()\n",
    "    time = x.strftime(\"%y-%m-%d_%H:%M:%S\")\n",
    "    model_checkpoint = os.path.join(configs['model_dir'], f'checkpoint_{time}_{epoch}.pth')\n",
    "    torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict()}, model_checkpoint)\n",
    "    logging.info(model_checkpoint)\n",
    "\n",
    "\n",
    "def test(test_loader, model, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    labels, distances = [], [] \n",
    "    for (data_a, data_p, label) in tqdm(test_loader):\n",
    "\n",
    "        if configs['use_cuda']:\n",
    "            data_a, data_p = data_a.cuda(), data_p.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_a = model(data_a)\n",
    "            out_p = model(data_p)\n",
    "        dists = torch.sqrt(torch.sum((out_a - out_p) ** 2, 1))  # euclidean distance\n",
    "        distances.append(dists.data.cpu().numpy().reshape(-1,1))\n",
    "        ll = label.data.cpu().numpy().reshape(-1, 1)\n",
    "        labels.append(ll)\n",
    "\n",
    "    num_tests = len(test_loader.dataset)\n",
    "    labels = np.vstack(labels).reshape(num_tests)\n",
    "    distances = np.vstack(distances).reshape(num_tests)\n",
    "\n",
    "    fpr95 = ErrorRateAt95Recall(labels, 1.0 / (distances + 1e-8))\n",
    "    logging.info('\\33[91mTest set: Accuracy(FPR95): {:.8f}\\n\\33[0m'.format(fpr95))\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def create_transform():\n",
    "    return transforms.Compose([#transforms.Lambda(cv2_scale),\n",
    "                               #transforms.Lambda(np_reshape),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((configs['dataset']['mean'],), (configs['dataset']['std'],))])\n",
    "\n",
    "def create_trainloader(root: str, train_scenes: list):   \n",
    "    dataset = TripletPhotoTour(root=root,\n",
    "                               transform=create_transform(),\n",
    "                               train_scenes=train_scenes)\n",
    "    return DataLoader(dataset, batch_size=configs['batch_size'], shuffle=True, num_workers=configs['n_workers'])\n",
    "\n",
    "def create_testloader(root: str, test_scene: str, is_challenge_data: bool):\n",
    "    if is_challenge_data:\n",
    "        dataset = TripletPhotoTour(root=root,\n",
    "                                   transform=create_transform(),\n",
    "                                   test_scene=test_scene,\n",
    "                                   train=False)\n",
    "    else:\n",
    "        dataset = BrownTest(root=root,\n",
    "                            scene=test_scene,\n",
    "                            transform=create_transform())\n",
    "    return DataLoader(dataset, batch_size=configs['batch_size'], shuffle=False, num_workers=configs['n_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Load brandenburg_gate dataset with n_points: 62398\n",
      "INFO:root:num_3d_points: 62398\n",
      "INFO:root:generate 62398 triplets (simple add a negative patch to a matched patch)\n",
      "100%|██████████| 62398/62398 [00:07<00:00, 8893.91it/s] \n"
     ]
    }
   ],
   "source": [
    "train_dataloader = create_trainloader(root=configs['dataset']['challenge_root'],\n",
    "                                      train_scenes=configs['dataset']['train_scenes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load test set: sacre_coeur\n",
      "INFO:root:load test set: st_peters_square\n",
      "INFO:root:load test set: reichstag\n"
     ]
    }
   ],
   "source": [
    "test_dataloaders = []\n",
    "for scene in configs['dataset']['test_scenes']['challenge']:\n",
    "    logging.info(f'load test set: {scene}')\n",
    "    dataloader = create_testloader(root=configs['dataset']['challenge_root'],\n",
    "                                   test_scene=scene,\n",
    "                                   is_challenge_data=True)\n",
    "    test_dataloaders.append((scene, dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = torch.tensor([\n",
    "    [1, 3, 1],\n",
    "    [2.0, 1, 3],\n",
    "    [1, -1, -5]], requires_grad=True)\n",
    "positive = torch.tensor([\n",
    "    [-1, 5, 2],\n",
    "    [-1.0, 0, 1],\n",
    "    [2, 2, 3]], requires_grad=True)\n",
    "# print(distance_matrix_vector(s, t) * distance_matrix_vector(s, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_sosnet(anchor, positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix_vector(anchor: torch.tensor, positive: torch.tensor, is_the_same=False) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    anchor, positive: batch_size x 512\n",
    "    return: batch_size x batch_size\n",
    "    \"\"\"    \n",
    "#     global n\n",
    "#     print(f'......{n}.....')\n",
    "    \n",
    "    d1_sq = torch.sum(anchor * anchor, dim=1).unsqueeze(-1)\n",
    "#     print(sum(sum(torch.isnan(d1_sq))))\n",
    "    d2_sq = torch.sum(positive * positive, dim=1).unsqueeze(-1)\n",
    "#     print(sum(sum(torch.isnan(d2_sq))))\n",
    "\n",
    "    eps = 1e-6\n",
    "    s1 = (d1_sq.repeat(1, positive.size(0)) + torch.t(d2_sq.repeat(1, anchor.size(0)))\n",
    "                      - 2.0 * torch.bmm(anchor.unsqueeze(0), torch.t(positive).unsqueeze(0)).squeeze(0))\n",
    "    if is_the_same:\n",
    "        eye = torch.eye(s1.size(1), requires_grad=True)\n",
    "        s1 = s1 + eye * 1\n",
    "    dist_matrix = torch.sqrt(s1 + eps)\n",
    "    \n",
    "\n",
    "\n",
    "    return dist_matrix\n",
    "\n",
    "def get_distance_matrix_without_min_on_diag(dist_matrix: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    dist_matrix: batch_size x batch_size\n",
    "    return: batch_size x batch_size\n",
    "    \"\"\"\n",
    "    eye = torch.eye(dist_matrix.size(1), requires_grad=True)\n",
    "    \n",
    "    # steps to filter out same patches that occur in distance matrix as negatives\n",
    "    dist_without_min_on_diag = dist_matrix + eye * 10\n",
    "    mask = (dist_without_min_on_diag.ge(0.008).float()-1.0)*(-1)\n",
    "    mask = mask.type_as(dist_without_min_on_diag)*10\n",
    "    dist_without_min_on_diag = dist_without_min_on_diag + mask\n",
    "    return dist_without_min_on_diag\n",
    "    \n",
    "    \n",
    "def loss_sosnet(anchor, positive):\n",
    "    \"\"\"HardNet margin loss - calculates loss based on distance matrix based on positive distance and closest negative distance.\n",
    "    \"\"\"\n",
    "\n",
    "    assert anchor.size() == positive.size(), \"Input sizes between positive and negative must be equal.\"\n",
    "    assert anchor.dim() == 2, \"Inputd must be a 2D matrix.\"\n",
    "    n = anchor.shape[0]\n",
    "    eps = 1e-8\n",
    "        \n",
    "    dist_matrix_a = distance_matrix_vector(anchor, anchor, True) + eps\n",
    "    dist_without_min_on_diag_a = get_distance_matrix_without_min_on_diag(dist_matrix_a)\n",
    "\n",
    "    dist_matrix = distance_matrix_vector(anchor, positive) + eps\n",
    "    pos1 = torch.diag(dist_matrix)\n",
    "    dist_without_min_on_diag = get_distance_matrix_without_min_on_diag(dist_matrix)\n",
    "\n",
    "    dist_matrix_p = distance_matrix_vector(positive, positive, True) + eps\n",
    "    dist_without_min_on_diag_p = get_distance_matrix_without_min_on_diag(dist_matrix_p)\n",
    "    \n",
    "    min_neg_a = torch.min(dist_without_min_on_diag_a,1)[0]\n",
    "    min_neg1 = torch.min(dist_without_min_on_diag,1)[0]\n",
    "    min_neg2 = torch.min(dist_without_min_on_diag,0)[0]\n",
    "    min_neg_p = torch.min(dist_without_min_on_diag_p, 1)[0]\n",
    "    \n",
    "    min_neg = torch.min(torch.min(min_neg1, min_neg2), torch.min(min_neg_a, min_neg_p))\n",
    "    pos = pos1\n",
    "\n",
    "    fos_loss = torch.clamp(1 + pos - min_neg, min=0.0)\n",
    "    fos_loss = torch.mean(fos_loss)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, indices_1 = torch.topk(dist_without_min_on_diag_a, k=8, dim=1, largest=False)\n",
    "        _, indices_2 = torch.topk(dist_without_min_on_diag_p, k=8, dim=1, largest=False)\n",
    "    mask = torch.zeros(n, n)\n",
    "    for i in range(mask.shape[0]):\n",
    "        mask[i][indices_1[i]] = 1\n",
    "        mask[i][indices_2[i]] = 1\n",
    "    \n",
    "    mask.requires_grad_(True)\n",
    "    s = (dist_without_min_on_diag_a - dist_without_min_on_diag_p) * (dist_without_min_on_diag_a - dist_without_min_on_diag_p)\n",
    "    s = mask * s\n",
    "    s = torch.sum(s, dim=1)\n",
    "    s = torch.sqrt(s + eps)\n",
    "    sos_loss = torch.mean(s)\n",
    "    return fos_loss + sos_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.4206409454345703\n",
      "1\n",
      "1.417121171951294\n",
      "2\n",
      "1.3818728923797607\n",
      "3\n",
      "1.3628431558609009\n",
      "4\n",
      "1.3414639234542847\n",
      "5\n",
      "1.3379077911376953\n",
      "6\n",
      "1.3174974918365479\n",
      "7\n",
      "1.3137112855911255\n",
      "8\n",
      "1.3036553859710693\n",
      "9\n",
      "1.2810842990875244\n",
      "10\n",
      "1.286557912826538\n",
      "11\n",
      "1.286529302597046\n",
      "12\n",
      "1.2682174444198608\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "model = HardNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=configs['lr'],\n",
    "                             betas=(0.9, 0.999),\n",
    "                             eps=1e-08,\n",
    "                             weight_decay=0,\n",
    "                             amsgrad=False)\n",
    "for batch_id, data in enumerate(train_dataloader):\n",
    "    if batch_id + 1 == len(train_dataloader):\n",
    "        continue\n",
    "    print(batch_id)\n",
    "    data_a, data_p = data\n",
    "#     with torch.no_grad():\n",
    "#         cache[batch_id] = (data_a, data_p, model.state_dict())\n",
    "    out_a = model(data_a)\n",
    "    out_p = model(data_p)\n",
    "#     print(out_a.shape, out_a[0][0:5])\n",
    "#     print(out_p.shape, out_p[0][0:5])\n",
    "#     print('*************')\n",
    "    loss = loss_sosnet(out_a, out_p)\n",
    "#     print('-------------')\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "#     print(loss)\n",
    "#     print(model.features[0].weight.grad[0][0][0])\n",
    "#     print(model.features[0].weight[0][0][0])\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        print(loss.item())\n",
    "#     print(model.features[0].weight[0][0][0])\n",
    "#     print('==============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SOSNet32x32()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = iter(train_dataloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_a = model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(out_a * out_a, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
