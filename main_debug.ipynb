{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import argparse\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from eval_metrics import ErrorRateAt95Recall\n",
    "from models import HardNet, ResNet, SOSNet32x32\n",
    "from dataset import TripletPhotoTour, BrownTest\n",
    "from losses import loss_HardNet, loss_L2Net\n",
    "from utils import cv2_scale, np_reshape, read_yaml\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('\\n\\n================ IMAGE MATCHING CHALLENGE 2020 ==================\\n\\n')\n",
    "configs = read_yaml('configs.yml')\n",
    "# models_output = os.path.join('models', configs['experiment_name'])\n",
    "os.makedirs(configs['model_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if configs['use_cuda']:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(configs['gpu_id'])\n",
    "    cudnn.benchmark = True\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_id, data in tqdm(enumerate(train_loader)):\n",
    "        if batch_id + 1 == len(train_loader):\n",
    "            continue\n",
    "        data_a, data_p = data\n",
    "\n",
    "        if configs['use_cuda']:\n",
    "            data_a, data_p  = data_a.cuda(), data_p.cuda()\n",
    "        out_a = model(data_a)\n",
    "        out_p = model(data_p)\n",
    "\n",
    "        loss = loss_HardNet(out_a, out_p)\n",
    "           \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_id%10 == 0:\n",
    "            logging.info(f'{batch_id}/{len(train_loader)} - Loss: {loss.item()}')\n",
    "        if batch_id%100 == 0:\n",
    "            x = datetime.datetime.now()\n",
    "            time = x.strftime(\"%y-%m-%d_%H:%M:%S\")\n",
    "            model_checkpoint = os.path.join(configs['model_dir'], f'checkpoint_{time}_{epoch}_{batch_id}.pth')\n",
    "            torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict()}, model_checkpoint)\n",
    "            logging.info(model_checkpoint)\n",
    "    logging.info(f'{len(train_loader)}/{len(train_loader)} - Loss: {loss.item()}')\n",
    "    \n",
    "    x = datetime.datetime.now()\n",
    "    time = x.strftime(\"%y-%m-%d_%H:%M:%S\")\n",
    "    model_checkpoint = os.path.join(configs['model_dir'], f'checkpoint_{time}_{epoch}.pth')\n",
    "    torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict()}, model_checkpoint)\n",
    "    logging.info(model_checkpoint)\n",
    "\n",
    "\n",
    "def test(test_loader, model, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    labels, distances = [], [] \n",
    "    for (data_a, data_p, label) in tqdm(test_loader):\n",
    "\n",
    "        if configs['use_cuda']:\n",
    "            data_a, data_p = data_a.cuda(), data_p.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out_a = model(data_a)\n",
    "            out_p = model(data_p)\n",
    "        dists = torch.sqrt(torch.sum((out_a - out_p) ** 2, 1))  # euclidean distance\n",
    "        distances.append(dists.data.cpu().numpy().reshape(-1,1))\n",
    "        ll = label.data.cpu().numpy().reshape(-1, 1)\n",
    "        labels.append(ll)\n",
    "\n",
    "    num_tests = len(test_loader.dataset)\n",
    "    labels = np.vstack(labels).reshape(num_tests)\n",
    "    distances = np.vstack(distances).reshape(num_tests)\n",
    "\n",
    "    fpr95 = ErrorRateAt95Recall(labels, 1.0 / (distances + 1e-8))\n",
    "    logging.info('\\33[91mTest set: Accuracy(FPR95): {:.8f}\\n\\33[0m'.format(fpr95))\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def create_transform():\n",
    "    return transforms.Compose([#transforms.Lambda(cv2_scale),\n",
    "                               #transforms.Lambda(np_reshape),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((configs['dataset']['mean'],), (configs['dataset']['std'],))])\n",
    "\n",
    "def create_trainloader(root: str, train_scenes: list):   \n",
    "    dataset = TripletPhotoTour(root=root,\n",
    "                               transform=create_transform(),\n",
    "                               train_scenes=train_scenes)\n",
    "    return DataLoader(dataset, batch_size=configs['batch_size'], shuffle=True, num_workers=configs['n_workers'])\n",
    "\n",
    "def create_testloader(root: str, test_scene: str, is_challenge_data: bool):\n",
    "    if is_challenge_data:\n",
    "        dataset = TripletPhotoTour(root=root,\n",
    "                                   transform=create_transform(),\n",
    "                                   test_scene=test_scene,\n",
    "                                   train=False)\n",
    "    else:\n",
    "        dataset = BrownTest(root=root,\n",
    "                            scene=test_scene,\n",
    "                            transform=create_transform())\n",
    "    return DataLoader(dataset, batch_size=configs['batch_size'], shuffle=False, num_workers=configs['n_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_trainloader(root=configs['dataset']['challenge_root'],\n",
    "                                      train_scenes=configs['dataset']['train_scenes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloaders = []\n",
    "for scene in configs['dataset']['test_scenes']['challenge']:\n",
    "    logging.info(f'load test set: {scene}')\n",
    "    dataloader = create_testloader(root=configs['dataset']['challenge_root'],\n",
    "                                   test_scene=scene,\n",
    "                                   is_challenge_data=True)\n",
    "    test_dataloaders.append((scene, dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=configs['lr'],\n",
    "                             betas=(0.9, 0.999),\n",
    "                             eps=1e-08,\n",
    "                             weight_decay=0,\n",
    "                             amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = torch.tensor([\n",
    "    [1, 3, 1],\n",
    "    [2.0, 1, 3],\n",
    "    [1, -1, -5]], requires_grad=True)\n",
    "positive = torch.tensor([\n",
    "    [-1, 5, 2],\n",
    "    [-1.0, 0, 1],\n",
    "    [2, 2, 3]], requires_grad=True)\n",
    "# print(distance_matrix_vector(s, t) * distance_matrix_vector(s, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix_vector(anchor: torch.tensor, positive: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    anchor, positive: batch_size x 512\n",
    "    return: batch_size x batch_size\n",
    "    \"\"\"    \n",
    "    d1_sq = torch.sum(anchor * anchor, dim=1).unsqueeze(-1)\n",
    "    d2_sq = torch.sum(positive * positive, dim=1).unsqueeze(-1)\n",
    "\n",
    "    eps = 1e-6\n",
    "    return torch.sqrt((d1_sq.repeat(1, positive.size(0)) + torch.t(d2_sq.repeat(1, anchor.size(0)))\n",
    "                      - 2.0 * torch.bmm(anchor.unsqueeze(0), torch.t(positive).unsqueeze(0)).squeeze(0))+eps)\n",
    "\n",
    "\n",
    "def get_distance_matrix_without_min_on_diag(dist_matrix: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    dist_matrix: batch_size x batch_size\n",
    "    return: batch_size x batch_size\n",
    "    \"\"\"\n",
    "    eye = torch.eye(dist_matrix.size(1), requires_grad=True)\n",
    "    \n",
    "    # steps to filter out same patches that occur in distance matrix as negatives\n",
    "    dist_without_min_on_diag = dist_matrix + eye * 10\n",
    "    mask = (dist_without_min_on_diag.ge(0.008).float()-1.0)*(-1)\n",
    "    mask = mask.type_as(dist_without_min_on_diag)*10\n",
    "    dist_without_min_on_diag = dist_without_min_on_diag + mask\n",
    "    return dist_without_min_on_diag\n",
    "    \n",
    "    \n",
    "def loss_sosnet(anchor, positive):\n",
    "    \"\"\"HardNet margin loss - calculates loss based on distance matrix based on positive distance and closest negative distance.\n",
    "    \"\"\"\n",
    "\n",
    "    assert anchor.size() == positive.size(), \"Input sizes between positive and negative must be equal.\"\n",
    "    assert anchor.dim() == 2, \"Inputd must be a 2D matrix.\"\n",
    "    eps = 1e-8\n",
    "    \n",
    "    dist_matrix_a = distance_matrix_vector(anchor, anchor) + eps\n",
    "#     print(dist_matrix_a * dist_matrix_a)\n",
    "    dist_without_min_on_diag_a = get_distance_matrix_without_min_on_diag(dist_matrix_a)\n",
    "#     print(dist_without_min_on_diag_a * dist_without_min_on_diag_a)\n",
    "\n",
    "    dist_matrix = distance_matrix_vector(anchor, positive) + eps\n",
    "#     print(dist_matrix * dist_matrix)\n",
    "    pos1 = torch.diag(dist_matrix)\n",
    "    dist_without_min_on_diag = get_distance_matrix_without_min_on_diag(dist_matrix)\n",
    "#     print(dist_without_min_on_diag * dist_without_min_on_diag)\n",
    "\n",
    "    dist_matrix_p = distance_matrix_vector(positive, positive) + eps\n",
    "#     print(dist_matrix_p * dist_matrix_p)\n",
    "    dist_without_min_on_diag_p = get_distance_matrix_without_min_on_diag(dist_matrix_p)\n",
    "#     print(dist_without_min_on_diag_p * dist_without_min_on_diag_p)\n",
    "\n",
    "    \n",
    "    min_neg_a = torch.min(dist_without_min_on_diag_a,1)[0]\n",
    "    min_neg1 = torch.min(dist_without_min_on_diag,1)[0]\n",
    "    min_neg2 = torch.min(dist_without_min_on_diag,0)[0]\n",
    "    min_neg_p = torch.min(dist_without_min_on_diag_p, 1)[0]\n",
    "    \n",
    "    min_neg = torch.min(torch.min(min_neg1, min_neg2), torch.min(min_neg_a, min_neg_p))\n",
    "\n",
    "    pos = pos1\n",
    "#     print(min_neg_a *min_neg_a)\n",
    "#     print(min_neg1 * min_neg1)\n",
    "#     print(min_neg2 * min_neg2)\n",
    "#     print(min_neg_p * min_neg_p)\n",
    "#     print(pos * pos)\n",
    "    loss = torch.clamp(1 + pos - min_neg, min=0.0)\n",
    "    loss = torch.mean(loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HardNet()\n",
    "cache = {}\n",
    "for batch_id, data in enumerate(train_dataloader):\n",
    "    if batch_id + 1 == len(train_dataloader):\n",
    "        continue\n",
    "    print(batch_id)\n",
    "    data_a, data_p = data\n",
    "    with torch.no_grad():\n",
    "        cache[batch_id] = (data_a, data_p, model.state_dict)\n",
    "    out_a = model(data_a)\n",
    "    out_p = model(data_p)\n",
    "    print(out_a.shape, out_a[0][0:5])\n",
    "    print(out_p.shape, out_p[0][0:5])\n",
    "    print('*************')\n",
    "    loss = loss_sosnet(out_a, out_p)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    print(model.features[0].weight.grad[0][0][0])\n",
    "    print(model.features[0].weight[0][0][0])\n",
    "    optimizer.step()\n",
    "    print(model.features[0].weight[0][0][0])\n",
    "    print('==============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a, data_p, M = cache[3]\n",
    "model_tmp = copy.deepcopy(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_a = model_tmp(data_a)\n",
    "out_p = model_tmp(data_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
